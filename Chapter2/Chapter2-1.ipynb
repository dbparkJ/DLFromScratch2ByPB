{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. 자연어와 단어의 분산 표현",
   "id": "16e8f1e364bb5bc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 자연어 처리란\n",
    "사람이 평소에 쓰는 말을 자연어(Natural Language)라고 한다.  \n",
    "자연어 처리(Natural Language Processing, NLP)를 문자 그대로 해석하면 자연어를 처리하는 분야라고 말한다."
   ],
   "id": "f7f00eb9b1937f8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1.1 단어의 의미\n",
    "컴퓨터에게 '단어의 의미'를 이해시키는 방법에는 크게 3가지 기법이 있다.  \n",
    "1. 시소러스를 활용한 기법  \n",
    "2. 통계 기반 기법  \n",
    "3. 추론 기반 기법"
   ],
   "id": "d7902f7e605d0828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 시소러스\n",
    "시소러스 방식은 단어의 의미를 직접적으로 나타내는 사전과 같은 방식이 아닌 유의어 사전으로, 뜻이 같은단어(동의어)나 뜻이 비슷한단어(유의어)로 구성되어 있다"
   ],
   "id": "f4fc75a78e08e810"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2.1 WordNet\n",
    "자연어 처리 분야에서 가장 유명한 시소러스는 WordNet이다.  \n",
    "WordNet은 프린스턴 대학교에서 1985년부터 구축한 시소러스로 지금까지 많은 연구와 다양한 자연어 처리 애플리케이션에서 활용되고 있다.  \n"
   ],
   "id": "994c11c6f56792c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91c80a545d96b89d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2.2 시소러스의 문제점\n",
    "WordNet과 같은 시소러스에는 수많은 단어에 대한 동의어와 계층 구조 등의 관계가 정의되어 있는데, 사람이 수작업으로 레이블링 하는 방식에는 큰 결점이 존재한다.  \n",
    "#### 시대 변화에 대응하기 어렵다.  \n",
    "단어의 뜻은 새로 생기거나 없어지기 때문에 시소러스의 문제 중 하나이다.  \n",
    "#### 사람을 쓰는 비용이 크다.  \n",
    "단어들 모두에 대해 단어 사이의 관계를 정의 해주어야 하는데 영어의 경우 한 단어에 비슷한 뜻은 약 1000만개 정도 된다.  \n",
    "#### 단어의 미묘한 차이를 표현할 수 없다.  \n",
    "비슷한 단어끼리 묶여있지만 비슷한 단어라도 미묘한 차이가 있는데 이 차이를 표현할 수 없다.  \n",
    "\n",
    "시소러스의 문제를 해결하기 위해 통계 기반 기법과 신경망을 사용한 추론 기반 기법을 활용하면 단어의 의미를 자동으로 추출한다.  "
   ],
   "id": "cd63ea3b3092eca2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 통계 기반 기법\n",
    "통계 기반 기법은 말뭉치(corpus 복수형, 단수 corpora)를 이용한다."
   ],
   "id": "50fb67bc0271eca3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3.1 파이썬으로 말뭉치 전처리 하기\n",
    "#### 1. Preprocessing\n",
    "텍스트 데이터를 단어로 분할하고 그 분할된 단어들을 단어 ID목록으로 변환한다."
   ],
   "id": "c2e0ffbdd231b8c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:23:01.077586Z",
     "start_time": "2024-06-30T12:23:01.070578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ],
   "id": "84e48f50487f2ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:23:05.489214Z",
     "start_time": "2024-06-30T12:23:05.476223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = text.split(' ')\n",
    "words"
   ],
   "id": "7334e8f1d19a0197",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "단어에 ID를 부여하고, ID의 리스트로 이용가능하게 해준다.(딕셔너리 사용)",
   "id": "730901880ab8487a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:24:29.247967Z",
     "start_time": "2024-06-30T12:24:29.234958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_to_id = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id =  len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        \n",
    "id_to_word = {id_: word for word, id_ in word_to_id.items()}"
   ],
   "id": "2c371372d107d47c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:24:36.123906Z",
     "start_time": "2024-06-30T12:24:36.116913Z"
    }
   },
   "cell_type": "code",
   "source": "id_to_word",
   "id": "f56c6bc34b195652",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:24:39.321131Z",
     "start_time": "2024-06-30T12:24:39.315136Z"
    }
   },
   "cell_type": "code",
   "source": "word_to_id",
   "id": "b9ea47aabadd48db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:24:46.974153Z",
     "start_time": "2024-06-30T12:24:46.955139Z"
    }
   },
   "cell_type": "code",
   "source": "id_to_word[1]",
   "id": "145214e21481c3a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:24:50.374637Z",
     "start_time": "2024-06-30T12:24:50.369464Z"
    }
   },
   "cell_type": "code",
   "source": "word_to_id['hello']",
   "id": "1e775a18a453e6cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:25:00.842344Z",
     "start_time": "2024-06-30T12:25:00.679322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 단어 목록 -> 단어 ID 목록으로 변경\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[word] for word in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ],
   "id": "eb0fe550f598eaff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:27:16.972614Z",
     "start_time": "2024-06-30T12:27:16.959607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id =  len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            \n",
    "    id_to_word = {id_: word for word, id_ in word_to_id.items()}\n",
    "    \n",
    "    corpus = np.array([word_to_id[word] for word in words])\n",
    "    return corpus, word_to_id, id_to_word"
   ],
   "id": "634c810bc7fefeb7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:27:17.098440Z",
     "start_time": "2024-06-30T12:27:17.092935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# common/util.py -> preprocess 메서드 사용\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ],
   "id": "442ed2d96a0aeab8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T12:27:17.222009Z",
     "start_time": "2024-06-30T12:27:17.216007Z"
    }
   },
   "cell_type": "code",
   "source": "corpus, word_to_id, id_to_word",
   "id": "9f86567d5bbc161f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 1, 5, 6]),\n",
       " {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6},\n",
       " {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3.2 단어의 분산표현\n",
    "단어의 의미를 정확하게 파악할 수 있는 벡터 표현을 자연어 처리 분야에서는 단어의 분산표현(distributional representation)이라고 한다."
   ],
   "id": "51e0884c0ad7936a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3.3 분포 가설\n",
    "단어의 의미는 주변단어에 의해 형성된다라는 것이 분포 가설(distributional hypothesis)라고 하며, 단어를 벡터로 표현하는 최근 연구도 대부분 이 가설에 기초한다."
   ],
   "id": "91a20bb3acc056f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  2.3.4 동시발생 행렬(Co-occurrence Matrix)\n",
    "주변 단어를 세어 보는 방법  \n",
    "특정 단어에 대해, 그 단어의 주변에 어떤 단어가 몇 번이나 등장하는지 카운팅하여 합치는 방법"
   ],
   "id": "714384deb0306e09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:39:12.922301Z",
     "start_time": "2024-06-30T13:39:12.907624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(f'corpus: {corpus}')\n",
    "print(f'id_to_word: {id_to_word}')"
   ],
   "id": "70dc086a407eee4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: [0 1 2 3 4 1 5 6]\n",
      "id_to_word: {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:43:57.967231Z",
     "start_time": "2024-06-30T13:43:57.952155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "C = np.array([[0, 1, 0, 0, 0, 0, 0], \n",
    "              [1, 0, 1, 0, 1, 1, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 0, 1, 0, 1, 0, 0], \n",
    "              [0, 1, 0, 1, 0, 0, 0], \n",
    "              [0, 1, 0, 0, 0, 0, 1], \n",
    "              [0, 0, 0, 0, 0, 1, 0]], dtype=np.int32)"
   ],
   "id": "49e8506d4068c0b9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:44:03.321401Z",
     "start_time": "2024-06-30T13:44:03.305871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ID가 0인 단어의 벡터 표현\n",
    "print(C[0])\n",
    "# ID가 4인 단어의 벡터 표현\n",
    "print(C[4])\n",
    "\n",
    "# \"goodbye\"의 벡터 표현\n",
    "print(C[word_to_id['goodbye']])"
   ],
   "id": "a3ea13636a20c55d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:45:28.479501Z",
     "start_time": "2024-06-30T13:45:28.469427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# common/util.py\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i  # left window_size\n",
    "            right_idx = idx + i  # right window_size\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ],
   "id": "979d7a4fdf673e73",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T13:45:33.664440Z",
     "start_time": "2024-06-30T13:45:33.656222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_size = 1\n",
    "vocab_size = len(id_to_word)\n",
    "\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "C"
   ],
   "id": "93cda49e4b0096a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3.5 벡터 간 유사도\n",
    "벡터 사이의 유사도를 측정하는 방법은 다양한데, 대표적으로 벡터의 내적이나 유클리드 거리 등을 꼽을 수 있다.  \n",
    "단어 벡터의 유사도를 나타낼 때는 코사인유사도(cosine similarity)를 자주 이용한다.  \n",
    "두방향이 완전히 같다면 1을 나타내고, 정 반대이면 -1을 나타낸다."
   ],
   "id": "183a02d507de322b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f778cfef319667bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
